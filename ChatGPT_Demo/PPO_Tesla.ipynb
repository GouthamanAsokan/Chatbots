{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRJapyV-cEwk",
        "outputId": "ce4710df-fc5a-4404-9278-04c3f752bc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pfrl@ git+https://github.com/voidful/pfrl.git\n",
            "  Cloning https://github.com/voidful/pfrl.git to /tmp/pip-install-zuoaggvk/pfrl_a82459c286ad4bd68eda8ae069510536\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/voidful/pfrl.git /tmp/pip-install-zuoaggvk/pfrl_a82459c286ad4bd68eda8ae069510536\n",
            "  Resolved https://github.com/voidful/pfrl.git to commit 2ad3d51a7a971f3fe7f2711f024be11642990d61\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.13.1+cu116)\n",
            "Requirement already satisfied: gym>=0.9.7 in /usr/local/lib/python3.8/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (3.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textrl==0.1.6 in /usr/local/lib/python3.8/dist-packages (0.1.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (from textrl==0.1.6) (4.26.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from textrl==0.1.6) (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->textrl==0.1.6) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym->textrl==0.1.6) (2.2.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym->textrl==0.1.6) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym->textrl==0.1.6) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->textrl==0.1.6) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->textrl==0.1.6) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym->textrl==0.1.6) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->textrl==0.1.6) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->textrl==0.1.6) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->textrl==0.1.6) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->textrl==0.1.6) (4.0.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#Step 1 install dependencies and load our fine-tuned model\n",
        "!pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
        "!pip install textrl==0.1.6\n",
        "from textrl import TextRLEnv,TextRLActor\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelWithLMHead\n",
        "import logging\n",
        "import sys\n",
        "import pfrl\n",
        "import torch\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"huggingtweets/elonmusk\")  \n",
        "model = AutoModelWithLMHead.from_pretrained(\"huggingtweets/elonmusk\")\n",
        "model.eval()\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# - Define a Reward model\n",
        "sentiment = pipeline('sentiment-analysis',model=\"cardiffnlp/twitter-roberta-base-sentiment\",tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment\",device=0,return_all_scores=True)\n",
        "transformers_logger = logging.getLogger('transformers')\n",
        "transformers_logger.setLevel(logging.CRITICAL)\n",
        "sentiment(\"dogecoin is bad\")\n",
        "sentiment(\"dogecoin is bad\")[0][0]['score']\n",
        "class MyRLEnv(TextRLEnv):\n",
        "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
        "      reward = 0\n",
        "      if finish or len(predicted_list) >= self.env_max_length:\n",
        "        if 1 < len(predicted_list):\n",
        "          predicted_text = tokenizer.convert_tokens_to_string(predicted_list)\n",
        "          # sentiment classifier\n",
        "          reward += sentiment(input_item[0]+predicted_text)[0][2]['score']\n",
        "      return reward"
      ],
      "metadata": {
        "id": "saTWP1mecOPk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(\"dogecoin is ok\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6RtspMyiquR",
        "outputId": "3ba21273-bb16-43ca-ca05-34be020fa91c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'LABEL_0', 'score': 0.01306374091655016},\n",
              "  {'label': 'LABEL_1', 'score': 0.3054283857345581},\n",
              "  {'label': 'LABEL_2', 'score': 0.6815078854560852}]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observaton_list = [['tesla is']]\n",
        "\n",
        "#Create a Reinforcement Learning Environment i.e Markov Decision Process\n",
        "\n",
        "# initialize the reward model using our fine-tuned model and one example prompt \n",
        "env = MyRLEnv(model, tokenizer, observation_input=observaton_list)\n",
        "\n",
        "# intialize the agent using the pre-trained model\n",
        "actor = TextRLActor(env,model,tokenizer)\n",
        "\n",
        "# Run reinforcement learning via PPO technique to maximize reward\n",
        "agent = actor.agent_ppo(update_interval=10, minibatch_size=10, epochs=10)\n",
        "\n",
        "# Test it\n",
        "actor.predict(observaton_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eCrl7lsqc7at",
        "outputId": "c7a5c875-f265-4d34-cca1-6c3e02210788"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' a real problem.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pfrl.experiments.train_agent_with_evaluation(\n",
        "    agent,\n",
        "    env,\n",
        "    steps=100,\n",
        "    eval_n_steps=None,\n",
        "    eval_n_episodes=1,       \n",
        "    train_max_episode_len=100,  \n",
        "    eval_interval=10,\n",
        "    outdir='tesla', \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V3vU-SbdOiH",
        "outputId": "203d23f9-7115-4463-b14e-e9c4878287ef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<textrl.actor.TextPPO at 0x7f136b6f3070>,\n",
              " [{'average_value': 2.2727895,\n",
              "   'average_entropy': 0.21261017,\n",
              "   'average_value_loss': 2.8386925935745237,\n",
              "   'average_policy_loss': -0.0921926562488082,\n",
              "   'n_updates': 10,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': 0.9697455167770386},\n",
              "  {'average_value': 1.4515439,\n",
              "   'average_entropy': 0.21450341,\n",
              "   'average_value_loss': 2.018683874607086,\n",
              "   'average_policy_loss': -0.051273139180848526,\n",
              "   'n_updates': 20,\n",
              "   'explained_variance': -3.0870882268405664,\n",
              "   'eval_score': 0.9875895380973816},\n",
              "  {'average_value': 1.2768729,\n",
              "   'average_entropy': 0.18776588,\n",
              "   'average_value_loss': 1.59937850634257,\n",
              "   'average_policy_loss': -0.05631556159894302,\n",
              "   'n_updates': 30,\n",
              "   'explained_variance': -36.592487966567504,\n",
              "   'eval_score': 0.005883386824280024},\n",
              "  {'average_value': 1.2428812,\n",
              "   'average_entropy': 0.19033684,\n",
              "   'average_value_loss': 1.2586446049809457,\n",
              "   'average_policy_loss': -0.04666200192878026,\n",
              "   'n_updates': 50,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': 0.008018381893634796},\n",
              "  {'average_value': 1.0199199,\n",
              "   'average_entropy': 0.17692035,\n",
              "   'average_value_loss': 1.0508378109761647,\n",
              "   'average_policy_loss': -0.03949609978872887,\n",
              "   'n_updates': 70,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': 0.7491190433502197},\n",
              "  {'average_value': 0.9522808,\n",
              "   'average_entropy': 0.19504115,\n",
              "   'average_value_loss': 0.947508112154901,\n",
              "   'average_policy_loss': -0.043179075251828215,\n",
              "   'n_updates': 80,\n",
              "   'explained_variance': -7.134354868950714,\n",
              "   'eval_score': 0.9550443291664124},\n",
              "  {'average_value': 0.8634536,\n",
              "   'average_entropy': 0.19797784,\n",
              "   'average_value_loss': 0.898907292717033,\n",
              "   'average_policy_loss': -0.04602884395216181,\n",
              "   'n_updates': 90,\n",
              "   'explained_variance': -0.6129253798260015,\n",
              "   'eval_score': 0.0030698352493345737},\n",
              "  {'average_value': 0.7609616,\n",
              "   'average_entropy': 0.1879233,\n",
              "   'average_value_loss': 0.8434183682501316,\n",
              "   'average_policy_loss': -0.044130212094285554,\n",
              "   'n_updates': 100,\n",
              "   'explained_variance': -1.506282633243305,\n",
              "   'eval_score': 0.9832257628440857}])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# - Evaluate\n",
        "agent.load(\"./tesla/best\")\n",
        "actor.predict(observaton_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LOcqcyvYdaM8",
        "outputId": "4a2c2180-321f-4310-9261-a3075c885b29"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the most beautiful part of the world'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}